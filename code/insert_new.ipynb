{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#########   KEY IN YOUR IP  #########\n",
    "client = MilvusClient(\n",
    "    uri=\"http://192.168.1.111:19530\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "model.to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_embedding(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model.get_image_features(**inputs)\n",
    "    outputs = outputs.cpu()  \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = input('Paste the path of your image here:')\n",
    "image_embedding = get_clip_embedding(image_path)\n",
    "image_embedding = image_embedding.detach().numpy()\n",
    "image_embedding = image_embedding.squeeze()\n",
    "image_embedding = np.array(image_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [image_embedding]\n",
    "res = client.search(\n",
    "    collection_name=\"image\", # Replace with the actual name of your collection\n",
    "    data=data,\n",
    "    limit=1,  # Max. number of search results to return\n",
    "    search_params={\"metric_type\": \"COSINE\", \"params\": {}}, # Search parameters\n",
    "    partition_names=[\"_default\"] # Partition names to search in\n",
    ")\n",
    "\n",
    "id = int(input('Key in id:'))\n",
    "xxx = input('Key in name:')\n",
    "\n",
    "partition_id = res[0][0]['id']\n",
    "print(partition_id)\n",
    "data = {\"id\": id, \"vector\": image_embedding, \"name\": xxx}\n",
    "res = client.insert(\n",
    "    collection_name=\"image\",\n",
    "    data=data,\n",
    "    partition_name=\"partition\"+str(partition_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
